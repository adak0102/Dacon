{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#MachinLearning Library\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Set Random Seed\n",
    "seed=777\n",
    "os.environ['PYTHONHASHED']=str(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 777\n",
      "Numpy: 1.18.5\n",
      "Pandas: 1.1.3\n",
      "LightGBM: 3.1.1\n",
      "Scikit-Learn: 0.23.2\n"
     ]
    }
   ],
   "source": [
    "# Print Information\n",
    "print('Seed: %i'%(seed))\n",
    "print('Numpy: %s'%(np.__version__))\n",
    "print('Pandas: %s'%(pd.__version__))\n",
    "print('LightGBM: %s'%(lgb.__version__))\n",
    "print('Scikit-Learn: %s'%(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dataset(dataset):\n",
    "    '''\n",
    "    This function sorts the meteric_id of train.csv and test.csv into numerical order.\n",
    "    '''\n",
    "    columns=dataset.columns\n",
    "    meter_ids=columns[1:] \n",
    "    tmp=[]\n",
    "    for meter_id in meter_ids:\n",
    "        meter_id=meter_id.replace('NX','')   #'NX'???\n",
    "        tmp.append(int(meter_id)) ##int???\n",
    "    tmp=np.sort(tmp)\n",
    "    \n",
    "    meter_ids=[]\n",
    "    for meter_id in tmp:\n",
    "        meter_id = 'X'+str(meter_id)\n",
    "        meter_ids.append(meter_id)\n",
    "        \n",
    "    results=[dataset[columns[0]].values]\n",
    "    for meter_id in meter_ids:\n",
    "        values=dataset[meter_id].values\n",
    "        results.append(values)\n",
    "    results=np.array(results).T\n",
    "    df=pd.DataFrame(results, columns=[columns[0]]+meter_ids)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Time    NX1    NX2    NX3    NX4  NX5    NX6    NX7    NX8  \\\n",
      "0      2016-07-26 11:00    NaN    NaN    NaN    NaN  NaN    NaN    NaN    NaN   \n",
      "1      2016-07-26 12:00    NaN    NaN    NaN    NaN  NaN    NaN    NaN    NaN   \n",
      "2      2016-07-26 13:00    NaN    NaN    NaN    NaN  NaN    NaN    NaN    NaN   \n",
      "3      2016-07-26 14:00    NaN    NaN    NaN    NaN  NaN    NaN    NaN    NaN   \n",
      "4      2016-07-26 15:00    NaN    NaN    NaN    NaN  NaN    NaN    NaN    NaN   \n",
      "...                 ...    ...    ...    ...    ...  ...    ...    ...    ...   \n",
      "16904  2018-06-30 19:00  0.271  0.754  0.327  0.468  NaN  0.314  0.769  0.790   \n",
      "16905  2018-06-30 20:00  0.341  0.827  0.478  0.356  NaN  0.434  0.680  0.819   \n",
      "16906  2018-06-30 21:00  0.535  0.516  0.558  0.496  NaN  0.479  0.590  0.910   \n",
      "16907  2018-06-30 22:00  0.379  0.494  0.605  0.320  NaN  0.555  0.604  1.044   \n",
      "16908  2018-06-30 23:00  0.388  0.482  0.651  0.284  NaN  0.452  0.629  1.116   \n",
      "\n",
      "         NX9  ...  NX1291  NX1292  NX1293  NX1294  NX1295  NX1296  NX1297  \\\n",
      "0        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "1        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "2        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "3        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "4        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "16904  0.558  ...   0.523   0.455   0.295   0.056   0.295   2.089   0.619   \n",
      "16905  0.470  ...   0.350   0.799   0.287   0.057   0.548   2.168   0.723   \n",
      "16906  0.424  ...   0.446   0.754   0.433   0.060   0.677   2.028   0.766   \n",
      "16907  0.412  ...   0.567   0.504   0.384   0.210   1.019   1.055   0.735   \n",
      "16908  0.400  ...   0.495   0.410   0.343   0.420   0.746   0.738   0.689   \n",
      "\n",
      "       NX1298  NX1299  NX1300  \n",
      "0         NaN     NaN     NaN  \n",
      "1         NaN     NaN     NaN  \n",
      "2         NaN     NaN     NaN  \n",
      "3         NaN     NaN     NaN  \n",
      "4         NaN     NaN     NaN  \n",
      "...       ...     ...     ...  \n",
      "16904   1.063   0.345   0.565  \n",
      "16905   4.760   0.388   0.620  \n",
      "16906   5.386   0.440   0.573  \n",
      "16907   7.150   0.393   0.629  \n",
      "16908   8.346   0.323   0.422  \n",
      "\n",
      "[16909 rows x 1301 columns]\n"
     ]
    }
   ],
   "source": [
    "d=pd.read_csv('train.csv')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pydatavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-39ea2a141873>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-e6b6dd038e0c>\u001b[0m in \u001b[0;36msort_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmeter_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmeter_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeter_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pydatavenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pydatavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X1'"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "train=sort_dataset(pd.read_csv('train.csv'))\n",
    "test=sort_dataset(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `pandas.fillna` not found.\n"
     ]
    }
   ],
   "source": [
    "pandas.fillna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "1. train,test의 결측치 모두 0으로 변경\n",
    "2. 날짜 타입을 datetime으로 변경\n",
    "3. 시간별 날씨 -> 평균을 이용해 -> 일자별 날씨로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(df_time,string_type='train'):\n",
    "    '''\n",
    "    This function changes format of time from string to datetime.\n",
    "    '''\n",
    "    old_times=df_time\n",
    "    new_times=old_times.copy()\n",
    "    for i, old_time in enumerate(old_times):\n",
    "        if string_type == 'train':\n",
    "            new_time = datetime.datetime.strptime(old_time, '%Y-%m-%d %H:%M' )\n",
    "        elif string_type == 'test':\n",
    "            new_time=datetime.datetime.strptime(old_time, '%Y.%m.%d %H:%M')\n",
    "        else:\n",
    "            new_time = datetime.datetime.strptime(old_time, '%Y-%m-%d')\n",
    "        new_times[i] = new_time\n",
    "    return new_times\n",
    "\n",
    "def split_day(_times, _dates):\n",
    "    '''\n",
    "    This function splits power consumption data and weather data by days.\n",
    "    '''\n",
    "    for time in _times:\n",
    "        if time.time().hour==0: #time.time().hour???\n",
    "            ref_time=time.date()  #time.date()????\n",
    "            break\n",
    "    times=[]\n",
    "    datas=[]\n",
    "    data_tmp=[]\n",
    "    for i,time in enumerate(_times):\n",
    "        time=time.date()\n",
    "        data=_datas[i]\n",
    "        if ref_time > time: #&gt;??? = 부등호 >\n",
    "            pass\n",
    "        elif ref_time == time:\n",
    "            data_tmp.append(data)\n",
    "        else:\n",
    "            times.append(ref_time)\n",
    "            datas.append(data_tmp)\n",
    "            ref_time = time\n",
    "            data_tmp = [data]\n",
    "    if ref_time not in times:\n",
    "        if len(data_tmp) == 24:\n",
    "            times.append(ref_time)\n",
    "            datas.append(data_tmp)\n",
    "    times = np.array(times)\n",
    "    datas = np.array(datas)\n",
    "    return times, datas\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        module\n",
       "\u001b[1;31mString form:\u001b[0m <module 'time' (built-in)>\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "This module provides various functions to manipulate time values.\n",
       "\n",
       "There are two standard representations of time.  One is the number\n",
       "of seconds since the Epoch, in UTC (a.k.a. GMT).  It may be an integer\n",
       "or a floating point number (to represent fractions of seconds).\n",
       "The Epoch is system-defined; on Unix, it is generally January 1st, 1970.\n",
       "The actual value can be retrieved by calling gmtime(0).\n",
       "\n",
       "The other representation is a tuple of 9 integers giving local time.\n",
       "The tuple items are:\n",
       "  year (including century, e.g. 1998)\n",
       "  month (1-12)\n",
       "  day (1-31)\n",
       "  hours (0-23)\n",
       "  minutes (0-59)\n",
       "  seconds (0-59)\n",
       "  weekday (0-6, Monday is 0)\n",
       "  Julian day (day in the year, 1-366)\n",
       "  DST (Daylight Savings Time) flag (-1, 0 or 1)\n",
       "If the DST flag is 0, the time is given in the regular time zone;\n",
       "if it is 1, the time is given in the DST time zone;\n",
       "if it is -1, mktime() should guess based on the date and time.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9c1496a81e34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Replace nan to zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Convert time data format to datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#Replace nan to zero\n",
    "train=train.replace(np.nan, 0.0)\n",
    "test=test.replace(np.nan,0.0)\n",
    "\n",
    "#Convert time data format to datetime\n",
    "train_times=time_convert(train['Time'], string_type='train').values\n",
    "test_times = time_convert(test['Time'], string_type='test').values\n",
    "#Meter id\n",
    "train_meter_ids = train.columns[1:]\n",
    "test_meter_ids=test.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling (a day)\n",
    "temperature = np.mean(split_day(add_times, temperature)[1], axis=1)\n",
    "rainfall = np.mean(split_day(add_times, rainfall)[1], axis=1)\n",
    "wind = np.mean(split_day(add_times, wind)[1], axis=1)\n",
    "humidity = np.mean(split_day(add_times, humidity)[1], axis=1)\n",
    "snowfall = np.mean(split_day(add_times, snowfall)[1], axis=1)\n",
    "add_times, cloud = split_day(add_times, cloud)\n",
    "cloud = np.mean(cloud, axis=1)\n",
    "\n",
    "# Make additional data set\n",
    "additional_data = np.array([   \n",
    "    add_times,\n",
    "    temperature,\n",
    "    rainfall,\n",
    "    wind,\n",
    "    humidity,\n",
    "    snowfall,\n",
    "    cloud,    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 탐색적 자료분석\n",
    "Exploratory Data Analysis\n",
    " test.csv는 id 481번 이하로 분포\n",
    " 모델 생성 시 0 ~ 481번 데이터만 사용하는 것을 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_num = []\n",
    "train_data_num = []\n",
    "for meter_id in train_meter_ids:\n",
    "    meter_num = int(meter_id.replace('X',''))\n",
    "    valid_num = len(np.where(train[meter_id]) > 0.0)[0])\n",
    "    train_id_num.append(meter_num)\n",
    "    train_data_num.append(valid_num)\n",
    "test_id_num=[]\n",
    "test_data_num=[]\n",
    "for meter_id in test_meter_ids:\n",
    "    meter_num = int(meter_id.replace('X',''))\n",
    "    valid_num = len(np.where(test[meter_id] > 0.0)[0]) # &gt; ???\n",
    "    test_id_num.append(meter_num)\n",
    "    test_data_num.append(valid_num)\n",
    "\n",
    "plt.scatter(train_id_num, train_data_num, s=5, color='b', label='train')\n",
    "plt.scatter(test_id_num, test_data_num, s=5, color='r', label='test')\n",
    "plt.legend()\n",
    "plt.xlim(0, 1500)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Meter Id')\n",
    "plt.ylabel('Data Numer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hansu(a):\n",
    "    count=0\n",
    "    for a in range(1,a+1):\n",
    "        if a <= 99:\n",
    "           count+=1\n",
    "\n",
    "        else:\n",
    "            lista=list(str(a)) #[1,2,3,4,6]\n",
    "            for i in range(1,len(lista)): #12346\n",
    "                if int(lista[i])-int(lista[i-1])==int(lista[1])-int(lista[0]):\n",
    "                    han=1\n",
    "                else:\n",
    "                    han=0\n",
    "                    break\n",
    "            if han==1:\n",
    "                count+=1\n",
    "    print(count)\n",
    "\n",
    "hansu(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. 변수 선택 및 모델 구축\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
